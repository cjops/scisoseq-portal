{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ce14992d1acec3bd4aa88f7128a526c5f0aa7d09fdb1e082a7bb5f361ee3013e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import pymongo\n",
    "from flask import Flask\n",
    "sys.path.append(\"gtex-pipeline/gene_model\")\n",
    "from collapse_annotation import collapse_annotation, Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "_client = MongoClient('localhost', 27017)\n",
    "_db = _client.gandallab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import InsertOne\n",
    "from pymongo.errors import BulkWriteError\n",
    "from pprint import pprint\n",
    "\n",
    "def attr_str_to_dict(s):\n",
    "    d = {}\n",
    "    for item in s.split(';')[:-1]:\n",
    "        item = item.strip().split(' ', maxsplit=1)\n",
    "        d[item[0]] = item[1].strip('\"')\n",
    "    return d\n",
    "\n",
    "def parse_gtf_line(line):\n",
    "    line = line.rstrip()\n",
    "    cols = line.split('\\t')\n",
    "    feature = {\n",
    "        'chromosome': cols[0],\n",
    "        'source': cols[1],\n",
    "        'feature_type': cols[2],\n",
    "        'start': int(cols[3]),\n",
    "        'end': int(cols[4]),\n",
    "        'score': cols[5],\n",
    "        'strand': cols[6],\n",
    "        'frame': cols[7]\n",
    "    }\n",
    "    feature.update(attr_str_to_dict(cols[8]))\n",
    "    return feature\n",
    "\n",
    "def mongo_bulk_write_genes(ops, count=0):\n",
    "    try:\n",
    "        _db.genes.bulk_write(ops, ordered=False)\n",
    "    except BulkWriteError as bwe:\n",
    "        pprint(bwe.details)\n",
    "    print('\\twrote', count+len(ops), 'genes to db')\n",
    "    return len(ops)\n",
    "\n",
    "def mongo_insert_gtf(f, name):\n",
    "    if _db.genes.find_one({'file': name}, {}):\n",
    "        print('\\tGTF already inserted')\n",
    "        return\n",
    "    \n",
    "    tx_count = 0\n",
    "    gene_count = 0\n",
    "    ops = []\n",
    "    current_gene = None\n",
    "\n",
    "    for line in f:\n",
    "        if line[0] == '#': continue\n",
    "\n",
    "        feat = parse_gtf_line(line)\n",
    "\n",
    "        if feat['feature_type'] == 'gene':\n",
    "            if current_gene:\n",
    "                ops.append(InsertOne({\n",
    "                    'file': name,\n",
    "                    'gene_id_short': current_gene['gene_id'].rsplit('.', maxsplit=1)[0],\n",
    "                    'gene': current_gene\n",
    "                }))\n",
    "            current_gene = feat\n",
    "            current_gene['transcripts'] = []\n",
    "        elif feat['feature_type'] == 'transcript':\n",
    "            current_gene['transcripts'].append(feat)\n",
    "            current_gene['transcripts'][-1]['exons'] = []\n",
    "            tx_count += 1\n",
    "            if tx_count % 1000 == 0:\n",
    "                print('\\tread', tx_count, 'transcripts from file')\n",
    "        elif feat['feature_type'] == 'exon':\n",
    "            current_gene['transcripts'][-1]['exons'].append(feat)\n",
    "        \n",
    "        if len(ops) >= 1000:\n",
    "            gene_count += mongo_bulk_write_genes(ops, gene_count)\n",
    "            ops = []\n",
    "    \n",
    "    if tx_count % 1000 != 0:\n",
    "        print('\\tread', tx_count, 'transcripts from file')\n",
    "    if current_gene:\n",
    "        ops.append(InsertOne({\n",
    "            'file': name,\n",
    "            'gene_id_short': current_gene['gene_id'].rsplit('.', maxsplit=1)[0],\n",
    "            'gene': current_gene\n",
    "        }))\n",
    "    if ops:\n",
    "        mongo_bulk_write_genes(ops, gene_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing gencode.v35lift37.annotation.gtf\n",
      "\tread 1000 transcripts from file\n",
      "\tread 2000 transcripts from file\n",
      "\tread 3000 transcripts from file\n",
      "\twrote 1000 genes to db\n",
      "\tread 4000 transcripts from file\n",
      "\tread 5000 transcripts from file\n",
      "\tread 6000 transcripts from file\n",
      "\tread 7000 transcripts from file\n",
      "\twrote 2000 genes to db\n",
      "\tread 8000 transcripts from file\n",
      "\tread 9000 transcripts from file\n",
      "\tread 10000 transcripts from file\n",
      "\tread 11000 transcripts from file\n",
      "\twrote 3000 genes to db\n",
      "\tread 12000 transcripts from file\n",
      "\tread 13000 transcripts from file\n",
      "\tread 14000 transcripts from file\n",
      "\twrote 4000 genes to db\n",
      "\tread 15000 transcripts from file\n",
      "\tread 16000 transcripts from file\n",
      "\tread 17000 transcripts from file\n",
      "\tread 18000 transcripts from file\n",
      "\twrote 5000 genes to db\n",
      "\tread 19000 transcripts from file\n",
      "\tread 20000 transcripts from file\n",
      "\tread 21000 transcripts from file\n",
      "\twrote 6000 genes to db\n",
      "\tread 22000 transcripts from file\n",
      "\tread 23000 transcripts from file\n",
      "\tread 24000 transcripts from file\n",
      "\tread 25000 transcripts from file\n",
      "\twrote 7000 genes to db\n",
      "\tread 26000 transcripts from file\n",
      "\tread 27000 transcripts from file\n",
      "\tread 28000 transcripts from file\n",
      "\tread 29000 transcripts from file\n",
      "\twrote 8000 genes to db\n",
      "\tread 30000 transcripts from file\n",
      "\tread 31000 transcripts from file\n",
      "\tread 32000 transcripts from file\n",
      "\twrote 9000 genes to db\n",
      "\tread 33000 transcripts from file\n",
      "\tread 34000 transcripts from file\n",
      "\tread 35000 transcripts from file\n",
      "\tread 36000 transcripts from file\n",
      "\twrote 10000 genes to db\n",
      "\tread 37000 transcripts from file\n",
      "\tread 38000 transcripts from file\n",
      "\tread 39000 transcripts from file\n",
      "\tread 40000 transcripts from file\n",
      "\tread 41000 transcripts from file\n",
      "\twrote 11000 genes to db\n",
      "\tread 42000 transcripts from file\n",
      "\tread 43000 transcripts from file\n",
      "\tread 44000 transcripts from file\n",
      "\tread 45000 transcripts from file\n",
      "\twrote 12000 genes to db\n",
      "\tread 46000 transcripts from file\n",
      "\tread 47000 transcripts from file\n",
      "\tread 48000 transcripts from file\n",
      "\tread 49000 transcripts from file\n",
      "\twrote 13000 genes to db\n",
      "\tread 50000 transcripts from file\n",
      "\tread 51000 transcripts from file\n",
      "\tread 52000 transcripts from file\n",
      "\tread 53000 transcripts from file\n",
      "\twrote 14000 genes to db\n",
      "\tread 54000 transcripts from file\n",
      "\tread 55000 transcripts from file\n",
      "\tread 56000 transcripts from file\n",
      "\tread 57000 transcripts from file\n",
      "\twrote 15000 genes to db\n",
      "\tread 58000 transcripts from file\n",
      "\tread 59000 transcripts from file\n",
      "\tread 60000 transcripts from file\n",
      "\twrote 16000 genes to db\n",
      "\tread 61000 transcripts from file\n",
      "\tread 62000 transcripts from file\n",
      "\tread 63000 transcripts from file\n",
      "\twrote 17000 genes to db\n",
      "\tread 64000 transcripts from file\n",
      "\tread 65000 transcripts from file\n",
      "\tread 66000 transcripts from file\n",
      "\tread 67000 transcripts from file\n",
      "\twrote 18000 genes to db\n",
      "\tread 68000 transcripts from file\n",
      "\tread 69000 transcripts from file\n",
      "\tread 70000 transcripts from file\n",
      "\tread 71000 transcripts from file\n",
      "\twrote 19000 genes to db\n",
      "\tread 72000 transcripts from file\n",
      "\tread 73000 transcripts from file\n",
      "\tread 74000 transcripts from file\n",
      "\twrote 20000 genes to db\n",
      "\tread 75000 transcripts from file\n",
      "\tread 76000 transcripts from file\n",
      "\tread 77000 transcripts from file\n",
      "\tread 78000 transcripts from file\n",
      "\twrote 21000 genes to db\n",
      "\tread 79000 transcripts from file\n",
      "\tread 80000 transcripts from file\n",
      "\tread 81000 transcripts from file\n",
      "\twrote 22000 genes to db\n",
      "\tread 82000 transcripts from file\n",
      "\tread 83000 transcripts from file\n",
      "\tread 84000 transcripts from file\n",
      "\tread 85000 transcripts from file\n",
      "\twrote 23000 genes to db\n",
      "\tread 86000 transcripts from file\n",
      "\tread 87000 transcripts from file\n",
      "\tread 88000 transcripts from file\n",
      "\twrote 24000 genes to db\n",
      "\tread 89000 transcripts from file\n",
      "\tread 90000 transcripts from file\n",
      "\tread 91000 transcripts from file\n",
      "\tread 92000 transcripts from file\n",
      "\twrote 25000 genes to db\n",
      "\tread 93000 transcripts from file\n",
      "\tread 94000 transcripts from file\n",
      "\tread 95000 transcripts from file\n",
      "\twrote 26000 genes to db\n",
      "\tread 96000 transcripts from file\n",
      "\tread 97000 transcripts from file\n",
      "\tread 98000 transcripts from file\n",
      "\twrote 27000 genes to db\n",
      "\tread 99000 transcripts from file\n",
      "\tread 100000 transcripts from file\n",
      "\tread 101000 transcripts from file\n",
      "\tread 102000 transcripts from file\n",
      "\tread 103000 transcripts from file\n",
      "\twrote 28000 genes to db\n",
      "\tread 104000 transcripts from file\n",
      "\tread 105000 transcripts from file\n",
      "\twrote 29000 genes to db\n",
      "\tread 106000 transcripts from file\n",
      "\tread 107000 transcripts from file\n",
      "\tread 108000 transcripts from file\n",
      "\twrote 30000 genes to db\n",
      "\tread 109000 transcripts from file\n",
      "\tread 110000 transcripts from file\n",
      "\tread 111000 transcripts from file\n",
      "\tread 112000 transcripts from file\n",
      "\twrote 31000 genes to db\n",
      "\tread 113000 transcripts from file\n",
      "\tread 114000 transcripts from file\n",
      "\tread 115000 transcripts from file\n",
      "\twrote 32000 genes to db\n",
      "\tread 116000 transcripts from file\n",
      "\tread 117000 transcripts from file\n",
      "\tread 118000 transcripts from file\n",
      "\tread 119000 transcripts from file\n",
      "\twrote 33000 genes to db\n",
      "\tread 120000 transcripts from file\n",
      "\tread 121000 transcripts from file\n",
      "\tread 122000 transcripts from file\n",
      "\tread 123000 transcripts from file\n",
      "\twrote 34000 genes to db\n",
      "\tread 124000 transcripts from file\n",
      "\tread 125000 transcripts from file\n",
      "\tread 126000 transcripts from file\n",
      "\tread 127000 transcripts from file\n",
      "\twrote 35000 genes to db\n",
      "\tread 128000 transcripts from file\n",
      "\tread 129000 transcripts from file\n",
      "\tread 130000 transcripts from file\n",
      "\tread 131000 transcripts from file\n",
      "\twrote 36000 genes to db\n",
      "\tread 132000 transcripts from file\n",
      "\tread 133000 transcripts from file\n",
      "\tread 134000 transcripts from file\n",
      "\tread 135000 transcripts from file\n",
      "\twrote 37000 genes to db\n",
      "\tread 136000 transcripts from file\n",
      "\tread 137000 transcripts from file\n",
      "\tread 138000 transcripts from file\n",
      "\tread 139000 transcripts from file\n",
      "\twrote 38000 genes to db\n",
      "\tread 140000 transcripts from file\n",
      "\tread 141000 transcripts from file\n",
      "\tread 142000 transcripts from file\n",
      "\tread 143000 transcripts from file\n",
      "\twrote 39000 genes to db\n",
      "\tread 144000 transcripts from file\n",
      "\tread 145000 transcripts from file\n",
      "\tread 146000 transcripts from file\n",
      "\twrote 40000 genes to db\n",
      "\tread 147000 transcripts from file\n",
      "\tread 148000 transcripts from file\n",
      "\tread 149000 transcripts from file\n",
      "\tread 150000 transcripts from file\n",
      "\twrote 41000 genes to db\n",
      "\tread 151000 transcripts from file\n",
      "\tread 152000 transcripts from file\n",
      "\tread 153000 transcripts from file\n",
      "\twrote 42000 genes to db\n",
      "\tread 154000 transcripts from file\n",
      "\tread 155000 transcripts from file\n",
      "\tread 156000 transcripts from file\n",
      "\tread 157000 transcripts from file\n",
      "\twrote 43000 genes to db\n",
      "\tread 158000 transcripts from file\n",
      "\tread 159000 transcripts from file\n",
      "\tread 160000 transcripts from file\n",
      "\twrote 44000 genes to db\n",
      "\tread 161000 transcripts from file\n",
      "\tread 162000 transcripts from file\n",
      "\tread 163000 transcripts from file\n",
      "\tread 164000 transcripts from file\n",
      "\twrote 45000 genes to db\n",
      "\tread 165000 transcripts from file\n",
      "\tread 166000 transcripts from file\n",
      "\tread 167000 transcripts from file\n",
      "\tread 168000 transcripts from file\n",
      "\tread 169000 transcripts from file\n",
      "\twrote 46000 genes to db\n",
      "\tread 170000 transcripts from file\n",
      "\tread 171000 transcripts from file\n",
      "\tread 172000 transcripts from file\n",
      "\twrote 47000 genes to db\n",
      "\tread 173000 transcripts from file\n",
      "\tread 174000 transcripts from file\n",
      "\tread 175000 transcripts from file\n",
      "\tread 176000 transcripts from file\n",
      "\twrote 48000 genes to db\n",
      "\tread 177000 transcripts from file\n",
      "\tread 178000 transcripts from file\n",
      "\tread 179000 transcripts from file\n",
      "\tread 180000 transcripts from file\n",
      "\tread 181000 transcripts from file\n",
      "\twrote 49000 genes to db\n",
      "\tread 182000 transcripts from file\n",
      "\tread 183000 transcripts from file\n",
      "\tread 184000 transcripts from file\n",
      "\tread 185000 transcripts from file\n",
      "\twrote 50000 genes to db\n",
      "\tread 186000 transcripts from file\n",
      "\tread 187000 transcripts from file\n",
      "\tread 188000 transcripts from file\n",
      "\tread 189000 transcripts from file\n",
      "\twrote 51000 genes to db\n",
      "\tread 190000 transcripts from file\n",
      "\tread 191000 transcripts from file\n",
      "\tread 192000 transcripts from file\n",
      "\tread 193000 transcripts from file\n",
      "\twrote 52000 genes to db\n",
      "\tread 194000 transcripts from file\n",
      "\tread 195000 transcripts from file\n",
      "\tread 196000 transcripts from file\n",
      "\tread 197000 transcripts from file\n",
      "\tread 198000 transcripts from file\n",
      "\twrote 53000 genes to db\n",
      "\tread 199000 transcripts from file\n",
      "\tread 200000 transcripts from file\n",
      "\tread 201000 transcripts from file\n",
      "\tread 202000 transcripts from file\n",
      "\twrote 54000 genes to db\n",
      "\tread 203000 transcripts from file\n",
      "\tread 204000 transcripts from file\n",
      "\tread 205000 transcripts from file\n",
      "\tread 206000 transcripts from file\n",
      "\tread 207000 transcripts from file\n",
      "\twrote 55000 genes to db\n",
      "\tread 208000 transcripts from file\n",
      "\tread 209000 transcripts from file\n",
      "\tread 210000 transcripts from file\n",
      "\tread 211000 transcripts from file\n",
      "\twrote 56000 genes to db\n",
      "\tread 212000 transcripts from file\n",
      "\tread 213000 transcripts from file\n",
      "\tread 214000 transcripts from file\n",
      "\twrote 57000 genes to db\n",
      "\tread 215000 transcripts from file\n",
      "\tread 216000 transcripts from file\n",
      "\tread 217000 transcripts from file\n",
      "\tread 218000 transcripts from file\n",
      "\twrote 58000 genes to db\n",
      "\tread 219000 transcripts from file\n",
      "\tread 220000 transcripts from file\n",
      "\tread 221000 transcripts from file\n",
      "\twrote 59000 genes to db\n",
      "\tread 222000 transcripts from file\n",
      "\tread 223000 transcripts from file\n",
      "\tread 224000 transcripts from file\n",
      "\tread 225000 transcripts from file\n",
      "\twrote 60000 genes to db\n",
      "\tread 226000 transcripts from file\n",
      "\tread 227000 transcripts from file\n",
      "\tread 228000 transcripts from file\n",
      "\twrote 61000 genes to db\n",
      "\tread 229000 transcripts from file\n",
      "\tread 230000 transcripts from file\n",
      "\twrote 62000 genes to db\n",
      "\tread 231000 transcripts from file\n",
      "\tread 231359 transcripts from file\n",
      "\twrote 62475 genes to db\n"
     ]
    }
   ],
   "source": [
    "gtfs_path = Path('/mnt/z/Gandal/GTF')\n",
    "for gtf in gtfs_path.glob('gencode*.gtf'):\n",
    "    print('Processing', gtf.name)\n",
    "    with open(gtf) as f:\n",
    "        mongo_insert_gtf(f, gtf.stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[SON([('v', 2), ('key', SON([('_id', 1)])), ('name', '_id_')]),\n",
       " SON([('v', 2), ('key', SON([('file', 1), ('gene.gene_name', 1)])), ('name', 'file_1_gene.gene_name_1')]),\n",
       " SON([('v', 2), ('key', SON([('gene.gene_name', 1)])), ('name', 'gene.gene_name_1')]),\n",
       " SON([('v', 2), ('key', SON([('gene.transcripts.transcript_id', 1)])), ('name', 'gene.transcripts.transcript_id_1')]),\n",
       " SON([('v', 2), ('key', SON([('gene_id_short', 1)])), ('name', 'gene_id_short_1')]),\n",
       " SON([('v', 2), ('key', SON([('file', 1), ('gene_id_short', 1)])), ('name', 'file_1_gene_id_short_1')])]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "_db.genes.drop_index('file_1_gene.gene_id_1')\n",
    "#_db.genes.create_index([('file', pymongo.ASCENDING), ('gene.gene_name', pymongo.ASCENDING)])\n",
    "_db.genes.create_index([('file', pymongo.ASCENDING), ('gene_id_short', pymongo.ASCENDING)])\n",
    "#_db.genes.create_index('gene.gene_name')\n",
    "#_db.genes.create_index('gene_id_short')\n",
    "#_db.genes.create_index('gene.transcripts.transcript_id')\n",
    "list(_db.genes.list_indexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n': 62475, 'ok': 1.0}"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "_db.genes.remove({'file': 'gencode.v35lift37.annotation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processed 1000 genes\n",
      "processed 2000 genes\n",
      "processed 3000 genes\n",
      "processed 4000 genes\n",
      "processed 5000 genes\n",
      "processed 6000 genes\n",
      "processed 7000 genes\n",
      "processed 8000 genes\n",
      "processed 9000 genes\n",
      "processed 10000 genes\n",
      "processed 11000 genes\n",
      "processed 12000 genes\n",
      "processed 13000 genes\n",
      "processed 14000 genes\n",
      "processed 15000 genes\n",
      "processed 16000 genes\n",
      "processed 17000 genes\n",
      "processed 18000 genes\n",
      "processed 19000 genes\n",
      "processed 20000 genes\n",
      "processed 21000 genes\n",
      "processed 22000 genes\n",
      "processed 23000 genes\n",
      "processed 24000 genes\n",
      "processed 25000 genes\n",
      "processed 26000 genes\n",
      "processed 27000 genes\n",
      "processed 28000 genes\n",
      "processed 29000 genes\n",
      "processed 30000 genes\n",
      "processed 31000 genes\n",
      "processed 32000 genes\n",
      "processed 33000 genes\n",
      "processed 34000 genes\n",
      "processed 35000 genes\n",
      "processed 36000 genes\n",
      "processed 37000 genes\n",
      "processed 38000 genes\n",
      "processed 39000 genes\n",
      "processed 40000 genes\n",
      "processed 41000 genes\n",
      "processed 42000 genes\n",
      "processed 43000 genes\n",
      "processed 44000 genes\n",
      "processed 45000 genes\n",
      "processed 46000 genes\n",
      "processed 47000 genes\n",
      "processed 48000 genes\n",
      "processed 49000 genes\n",
      "processed 50000 genes\n",
      "processed 51000 genes\n",
      "processed 52000 genes\n",
      "processed 53000 genes\n",
      "processed 54000 genes\n",
      "processed 55000 genes\n",
      "processed 56000 genes\n",
      "processed 57000 genes\n",
      "processed 58000 genes\n",
      "processed 59000 genes\n",
      "processed 60000 genes\n",
      "processed 61000 genes\n",
      "processed 62000 genes\n",
      "processed 63000 genes\n",
      "processed 64000 genes\n",
      "processed 65000 genes\n",
      "processed 66000 genes\n",
      "processed 67000 genes\n",
      "processed 68000 genes\n",
      "processed 69000 genes\n",
      "processed 70000 genes\n",
      "processed 71000 genes\n",
      "processed 72000 genes\n",
      "processed 73000 genes\n",
      "processed 74000 genes\n",
      "processed 75000 genes\n",
      "processed 76000 genes\n",
      "processed 77000 genes\n",
      "processed 78000 genes\n"
     ]
    }
   ],
   "source": [
    "# add missing gene_id_short fields - this should not be needed to be run again\n",
    "count = 0\n",
    "for gene in _db.genes.find({}, {'gene_id_short': 1, 'gene.gene_id': 1}):\n",
    "    if 'gene_id_short' not in gene:\n",
    "        gene_id_short = gene['gene']['gene_id'].rsplit('.', maxsplit=1)[0]\n",
    "        _db.genes.update_one({'_id': gene['_id']}, {'$set': {'gene_id_short': gene_id_short}})\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print('processed', count, 'genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "_db.genes.count({'gene_id_short': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "78156\n",
      "60225\n",
      "62930\n",
      "63116\n"
     ]
    }
   ],
   "source": [
    "print(_db.genes.count())\n",
    "print(len(_db.genes.distinct('gene.gene_name')))\n",
    "print(len(_db.genes.distinct('gene_id_short')))\n",
    "print(len(list(_db.genes.aggregate([{'$group': {'_id': {'gene_name': \"$gene.gene_name\", 'gene_id': \"$gene_id_short\"}}}]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_selectize(f, gene_file=None):\n",
    "    filter = {'file': gene_file} if gene_file else {}\n",
    "    selectize = sorted(_db.genes.distinct('gene.gene_name', filter))\n",
    "    f.write('function getSelectizeOptions(){ return ')\n",
    "    json.dump([{'v': x} for x in selectize], f)\n",
    "    f.write('; }')\n",
    "    if hasattr(f, 'name'):\n",
    "        print('Wrote', len(selectize), 'gene symbols to', f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15681\n15681\n"
     ]
    }
   ],
   "source": [
    "print(_db.genes.count({'file': 'All_unfiltered_128k_multiexon_A0.75_minRead3_talon'}))\n",
    "print(len(_db.genes.distinct('gene_id_short', {'file': 'All_unfiltered_128k_multiexon_A0.75_minRead3_talon'})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = list(_db.genes.aggregate([\n",
    "    {'$match': {'file': 'All_unfiltered_128k_multiexon_A0.75_minRead3_talon'}},\n",
    "    {'$group': {'_id': '$gene.gene_name', 'gene_id': {'$push': '$gene_id_short'}}},\n",
    "    {'$project': {'gene_name': '$_id', 'gene_id': '$gene_id', '_id': 0}}\n",
    "]))\n",
    "selectize = []\n",
    "for x in g:\n",
    "    if len(x['gene_id']) > 1:\n",
    "        for id in x['gene_id']:\n",
    "            selectize.append({\n",
    "                'text': ' - '.join([x['gene_name'], id]),\n",
    "                'value': id\n",
    "            })\n",
    "    else:\n",
    "        selectize.append({\n",
    "            'text': x['gene_name'],\n",
    "            'value': x['gene_id'][0]\n",
    "        })\n",
    "selectize.sort(key=lambda x: x['text'])\n",
    "#for x in selectize[:10]:\n",
    "#    print(x)\n",
    "#for x in selectize:\n",
    "#    if ' - ' in x['text']:\n",
    "#        print(x)\n",
    "\n",
    "# abandoning this - let's stick with gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wrote 15672 gene symbols to all_symbols.js\n"
     ]
    }
   ],
   "source": [
    "with open('all_symbols.js', 'w') as f:\n",
    "    generate_selectize(f, 'All_unfiltered_128k_multiexon_A0.75_minRead3_talon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_union(intervals):\n",
    "    \"\"\"\n",
    "    Returns the union of all intervals in the input list\n",
    "      intervals: list of tuples or 2-element lists\n",
    "    \"\"\"\n",
    "    intervals.sort(key=lambda x: x[0])\n",
    "    union = [intervals[0]]\n",
    "    for i in intervals[1:]:\n",
    "        if i[0] <= union[-1][1]:  # overlap w/ previous\n",
    "            if i[1] > union[-1][1]:  # only extend if larger\n",
    "                union[-1][1] = i[1]\n",
    "        else:\n",
    "            union.append(i)\n",
    "    return union\n",
    "\n",
    "def mongo_bulk_write_model(ops, count=0):\n",
    "    try:\n",
    "        _db.model_exons.bulk_write(ops, ordered=False)\n",
    "    except BulkWriteError as bwe:\n",
    "        pprint(bwe.details)\n",
    "    print('\\twrote', count+len(ops), 'genes to db')\n",
    "    return len(ops)\n",
    "\n",
    "def mongo_collapse_transcripts(file1, files2=[]):\n",
    "    genes = _db.genes.distinct('gene.gene_name', {'file': file1})\n",
    "    filter = {'file': {'$in': files2}} if files2 else {}\n",
    "    print(len(genes))\n",
    "    ops = []\n",
    "    count = 0\n",
    "    for gene in genes:\n",
    "        exon_coords = []\n",
    "        model = []\n",
    "        results = list(_db.genes.find(\n",
    "            {'gene.gene_name': gene, **filter},\n",
    "            {'gene.chromosome': 1, 'gene.strand': 1, 'gene.transcripts.transcript_type': 1, 'gene.transcripts.exons.start': 1, 'gene.transcripts.exons.end': 1}\n",
    "        ))\n",
    "        chrom = results[0]['gene']['chromosome']\n",
    "        strand = results[0]['gene']['strand']\n",
    "        for document in results:\n",
    "            for transcript in document['gene']['transcripts']:\n",
    "                if transcript.get('transcript_type') == 'retained_intron':\n",
    "                    continue\n",
    "                for exon in transcript['exons']:\n",
    "                    exon_coords.append([exon['start'], exon['end']])\n",
    "        new_coords = interval_union(exon_coords)\n",
    "        #start_pos = np.min([i[0] for i in new_coords])\n",
    "        #end_pos = np.max([i[1] for i in new_coords])\n",
    "        if strand == '-':\n",
    "            new_coords.reverse()\n",
    "        for i, (start, end) in enumerate(new_coords, 1):\n",
    "            model.append({\n",
    "                'chromosome': chrom,\n",
    "                'strand': strand,\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'exon_id': '_'.join([gene, str(i)]),\n",
    "                'exon_number': i\n",
    "            })\n",
    "        ops.append(InsertOne({\n",
    "            'gene_name': gene,\n",
    "            'exons': model\n",
    "        }))\n",
    "        if len(ops) >= 1000:\n",
    "            count += mongo_bulk_write_model(ops, count)\n",
    "            ops = []\n",
    "    if ops:\n",
    "        mongo_bulk_write_model(ops, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15672\n",
      "\twrote 1000 genes to db\n",
      "\twrote 2000 genes to db\n",
      "\twrote 3000 genes to db\n",
      "\twrote 4000 genes to db\n",
      "\twrote 5000 genes to db\n",
      "\twrote 6000 genes to db\n",
      "\twrote 7000 genes to db\n",
      "\twrote 8000 genes to db\n",
      "\twrote 9000 genes to db\n",
      "\twrote 10000 genes to db\n",
      "\twrote 11000 genes to db\n",
      "\twrote 12000 genes to db\n",
      "\twrote 13000 genes to db\n",
      "\twrote 14000 genes to db\n",
      "\twrote 15000 genes to db\n",
      "\twrote 15672 genes to db\n"
     ]
    }
   ],
   "source": [
    "mongo_collapse_transcripts('All_unfiltered_128k_multiexon_A0.75_minRead3_talon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[SON([('v', 2), ('key', SON([('_id', 1)])), ('name', '_id_')]),\n",
       " SON([('v', 2), ('unique', True), ('key', SON([('gene_name', 1)])), ('name', 'gene_name_1')])]"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "_db.model_exons.create_index('gene_name', unique=True)\n",
    "list(_db.model_exons.list_indexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongo_add_expression(f, gene_file):\n",
    "    tx = {}\n",
    "    for i,line in enumerate(f):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        tokens = line.split()\n",
    "        tx_id = tokens[3].replace('-', '_')\n",
    "        cell_type = tokens[4]\n",
    "        avg_exp = float(tokens[1])\n",
    "        pct_exp = float(tokens[2])\n",
    "        avg_exp_scaled = float(tokens[5])\n",
    "        if tx_id not in tx:\n",
    "            tx[tx_id] = {}\n",
    "        tx[tx_id][cell_type] = [avg_exp, pct_exp, avg_exp_scaled]\n",
    "    print(len(tx), 'total transcripts')\n",
    "    write_count = 0\n",
    "    other_count = 0\n",
    "    no_match_count = 0\n",
    "    for tx_id in tx:\n",
    "        exp = [dict(zip(['cell_type', 'avg_exp', 'pct_exp', 'avg_exp_scaled'], [k]+v)) for k,v in tx[tx_id].items()]\n",
    "        db_results = {x['file']: x['_id'] for x in _db.genes.find({'gene.transcripts.transcript_id': tx_id}, {'file': 1})}\n",
    "        if gene_file in db_results:\n",
    "            _db.genes.update_one(\n",
    "                {'_id': db_results[gene_file], 'gene.transcripts.transcript_id': tx_id},\n",
    "                {'$set': {'gene.transcripts.$.expression': exp}}\n",
    "            )\n",
    "            write_count += 1\n",
    "        elif len(db_results) > 0:\n",
    "            other_count += 1\n",
    "        else:\n",
    "            no_match_count += 1\n",
    "        if write_count % 1000 == 0:\n",
    "            print('wrote', write_count, 'transcripts to db')\n",
    "    if write_count % 1000 != 0:\n",
    "        print('wrote', write_count, 'transcripts to db')\n",
    "    if other_count > 0:\n",
    "        print(other_count, 'transcripts in db but not under', gene_file)\n",
    "    if no_match_count > 0:\n",
    "        print(no_match_count, 'transcripts not found in db')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "112134 total transcripts\n",
      "wrote 1000 transcripts to db\n",
      "wrote 2000 transcripts to db\n",
      "wrote 3000 transcripts to db\n",
      "wrote 4000 transcripts to db\n",
      "wrote 5000 transcripts to db\n",
      "wrote 6000 transcripts to db\n",
      "wrote 7000 transcripts to db\n",
      "wrote 8000 transcripts to db\n",
      "wrote 9000 transcripts to db\n",
      "wrote 10000 transcripts to db\n",
      "wrote 11000 transcripts to db\n",
      "wrote 12000 transcripts to db\n",
      "wrote 13000 transcripts to db\n",
      "wrote 13000 transcripts to db\n",
      "wrote 14000 transcripts to db\n",
      "wrote 15000 transcripts to db\n",
      "wrote 16000 transcripts to db\n",
      "wrote 17000 transcripts to db\n",
      "wrote 18000 transcripts to db\n",
      "wrote 19000 transcripts to db\n",
      "wrote 20000 transcripts to db\n",
      "wrote 21000 transcripts to db\n",
      "wrote 22000 transcripts to db\n",
      "wrote 23000 transcripts to db\n",
      "wrote 24000 transcripts to db\n",
      "wrote 25000 transcripts to db\n",
      "wrote 26000 transcripts to db\n",
      "wrote 27000 transcripts to db\n",
      "wrote 28000 transcripts to db\n",
      "wrote 29000 transcripts to db\n",
      "wrote 29000 transcripts to db\n",
      "wrote 30000 transcripts to db\n",
      "wrote 31000 transcripts to db\n",
      "wrote 32000 transcripts to db\n",
      "wrote 33000 transcripts to db\n",
      "wrote 34000 transcripts to db\n",
      "wrote 35000 transcripts to db\n",
      "wrote 36000 transcripts to db\n",
      "wrote 37000 transcripts to db\n",
      "wrote 38000 transcripts to db\n",
      "wrote 39000 transcripts to db\n",
      "wrote 40000 transcripts to db\n",
      "wrote 41000 transcripts to db\n",
      "wrote 42000 transcripts to db\n",
      "wrote 43000 transcripts to db\n",
      "wrote 44000 transcripts to db\n",
      "wrote 45000 transcripts to db\n",
      "wrote 46000 transcripts to db\n",
      "wrote 47000 transcripts to db\n",
      "wrote 48000 transcripts to db\n",
      "wrote 49000 transcripts to db\n",
      "wrote 50000 transcripts to db\n",
      "wrote 51000 transcripts to db\n",
      "wrote 52000 transcripts to db\n",
      "wrote 53000 transcripts to db\n",
      "wrote 54000 transcripts to db\n",
      "wrote 55000 transcripts to db\n",
      "wrote 56000 transcripts to db\n",
      "wrote 57000 transcripts to db\n",
      "wrote 58000 transcripts to db\n",
      "wrote 59000 transcripts to db\n",
      "wrote 60000 transcripts to db\n",
      "wrote 61000 transcripts to db\n",
      "wrote 62000 transcripts to db\n",
      "wrote 63000 transcripts to db\n",
      "wrote 64000 transcripts to db\n",
      "wrote 65000 transcripts to db\n",
      "wrote 66000 transcripts to db\n",
      "wrote 67000 transcripts to db\n",
      "wrote 68000 transcripts to db\n",
      "wrote 69000 transcripts to db\n",
      "wrote 70000 transcripts to db\n",
      "wrote 71000 transcripts to db\n",
      "wrote 72000 transcripts to db\n",
      "wrote 73000 transcripts to db\n",
      "wrote 74000 transcripts to db\n",
      "wrote 75000 transcripts to db\n",
      "wrote 76000 transcripts to db\n",
      "wrote 77000 transcripts to db\n",
      "wrote 78000 transcripts to db\n",
      "wrote 79000 transcripts to db\n",
      "wrote 80000 transcripts to db\n",
      "wrote 81000 transcripts to db\n",
      "wrote 82000 transcripts to db\n",
      "wrote 83000 transcripts to db\n",
      "wrote 84000 transcripts to db\n",
      "wrote 85000 transcripts to db\n",
      "wrote 86000 transcripts to db\n",
      "wrote 87000 transcripts to db\n",
      "wrote 88000 transcripts to db\n",
      "wrote 89000 transcripts to db\n",
      "wrote 90000 transcripts to db\n",
      "wrote 91000 transcripts to db\n",
      "wrote 92000 transcripts to db\n",
      "wrote 93000 transcripts to db\n",
      "wrote 94000 transcripts to db\n",
      "wrote 95000 transcripts to db\n",
      "wrote 96000 transcripts to db\n",
      "wrote 97000 transcripts to db\n",
      "wrote 98000 transcripts to db\n",
      "wrote 99000 transcripts to db\n",
      "wrote 100000 transcripts to db\n",
      "wrote 101000 transcripts to db\n",
      "wrote 102000 transcripts to db\n",
      "wrote 103000 transcripts to db\n",
      "wrote 104000 transcripts to db\n",
      "wrote 105000 transcripts to db\n",
      "wrote 106000 transcripts to db\n",
      "wrote 107000 transcripts to db\n",
      "wrote 108000 transcripts to db\n",
      "wrote 108128 transcripts to db\n",
      "3698 transcripts in db but not under All_unfiltered_128k_multiexon_A0.75_minRead3_talon\n",
      "308 transcripts not found in db\n"
     ]
    }
   ],
   "source": [
    "with open('/mnt/z/Gandal/expression/Isoform_Average_percent_expression.txt') as f:\n",
    "    mongo_add_expression(f, 'All_unfiltered_128k_multiexon_A0.75_minRead3_talon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}